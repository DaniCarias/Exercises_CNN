Dataset: ./data/cats_dogs_full/train and ./data/cats_dogs_full/test
Train dataloader: 624 batches
Test dataloader: 157 batches
--------Epoch: 0
-Training...
Batch: 0/624
/home/danielcarias/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/danielcarias/.local/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:870: UserWarning: Truncated File Read
  warnings.warn(str(msg))
Batch: 400/624
Per batch -> Train Loss: 0.8132561445236206 | Train Accuracy: 50.00%
-Testing...
Batch: 0/157
Batch: 50/157
Batch: 100/157
Batch: 150/157
Per batch -> Test Loss: 0.8184376955032349 | Test Accuracy: 49.48%
--------Epoch: 1
-Training...
Batch: 0/624
/home/danielcarias/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Batch: 400/624
/home/danielcarias/.local/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:870: UserWarning: Truncated File Read
  warnings.warn(str(msg))
Per batch -> Train Loss: 0.8132628798484802 | Train Accuracy: 50.00%
-Testing...
Batch: 0/157
Batch: 50/157
Batch: 100/157
Batch: 150/157
Per batch -> Test Loss: 0.8184376955032349 | Test Accuracy: 49.48%
--------Epoch: 2
-Training...
Batch: 0/624
Traceback (most recent call last):
  File "/home/danielcarias/Documents/Estudo NN/Estudo/CNN/first_project/CNN.py", line 155, in <module>
    train_loss, train_acc = train_model(model, train_dataloader, loss_fn, optimizer)
  File "/home/danielcarias/Documents/Estudo NN/Estudo/CNN/first_project/CNN.py", line 49, in train_model
    for batch, (X, y) in enumerate(data_loader):
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torchvision/datasets/folder.py", line 231, in __getitem__
    sample = self.transform(sample)
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torchvision/transforms/transforms.py", line 137, in __call__
    return F.to_tensor(pic)
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torchvision/transforms/functional.py", line 175, in to_tensor
    return img.to(dtype=default_float_dtype).div(255)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/danielcarias/Documents/Estudo NN/Estudo/CNN/first_project/CNN.py", line 155, in <module>
    train_loss, train_acc = train_model(model, train_dataloader, loss_fn, optimizer)
  File "/home/danielcarias/Documents/Estudo NN/Estudo/CNN/first_project/CNN.py", line 49, in train_model
    for batch, (X, y) in enumerate(data_loader):
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torchvision/datasets/folder.py", line 231, in __getitem__
    sample = self.transform(sample)
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torchvision/transforms/transforms.py", line 137, in __call__
    return F.to_tensor(pic)
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torchvision/transforms/functional.py", line 175, in to_tensor
    return img.to(dtype=default_float_dtype).div(255)
KeyboardInterrupt