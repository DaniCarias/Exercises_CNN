Labels: 10
--------Epoch: 0
-Training...
Batch: 0/3750
Batch: 400/3750
Batch: 800/3750
Batch: 1200/3750
Batch: 1600/3750
Batch: 2000/3750
Batch: 2400/3750
Batch: 2800/3750
Batch: 3200/3750
Batch: 3600/3750
Per batch -> Train Loss: 2.304074287414551 | Train Accuracy: 9.99%
-Testing...
Batch: 0/625
Batch: 50/625
Batch: 100/625
Batch: 150/625
Batch: 200/625
Batch: 250/625
Batch: 300/625
Batch: 350/625
Batch: 400/625
Batch: 450/625
Batch: 500/625
Batch: 550/625
Batch: 600/625
Per batch -> Test Loss: 2.304361581802368 | Test Accuracy: 10.00%
--------Epoch: 1
-Training...
Batch: 0/3750
Batch: 400/3750
Batch: 800/3750
Batch: 1200/3750
Batch: 1600/3750
Traceback (most recent call last):
  File "/home/danielcarias/Documents/Estudo NN/Estudo/CNN/first_project/CNN.py", line 153, in <module>
    train_loss, train_acc = train_model(model, train_dataloader, loss_fn, optimizer)
  File "/home/danielcarias/Documents/Estudo NN/Estudo/CNN/first_project/CNN.py", line 65, in train_model
    for batch, (X, y) in enumerate(data_loader):
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torchvision/datasets/mnist.py", line 145, in __getitem__
    img = self.transform(img)
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torchvision/transforms/transforms.py", line 137, in __call__
    return F.to_tensor(pic)
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torchvision/transforms/functional.py", line 167, in to_tensor
    img = torch.from_numpy(np.array(pic, mode_to_nptype.get(pic.mode, np.uint8), copy=True))
  File "/home/danielcarias/.local/lib/python3.10/site-packages/PIL/Image.py", line 681, in __array_interface__
    new["data"] = self.tobytes()
  File "/home/danielcarias/.local/lib/python3.10/site-packages/PIL/Image.py", line 746, in tobytes
    e = _getencoder(self.mode, encoder_name, args)
  File "/home/danielcarias/.local/lib/python3.10/site-packages/PIL/Image.py", line 416, in _getencoder
    encoder = getattr(core, encoder_name + "_encoder")
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/danielcarias/Documents/Estudo NN/Estudo/CNN/first_project/CNN.py", line 153, in <module>
    train_loss, train_acc = train_model(model, train_dataloader, loss_fn, optimizer)
  File "/home/danielcarias/Documents/Estudo NN/Estudo/CNN/first_project/CNN.py", line 65, in train_model
    for batch, (X, y) in enumerate(data_loader):
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torchvision/datasets/mnist.py", line 145, in __getitem__
    img = self.transform(img)
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torchvision/transforms/transforms.py", line 137, in __call__
    return F.to_tensor(pic)
  File "/home/danielcarias/.local/lib/python3.10/site-packages/torchvision/transforms/functional.py", line 167, in to_tensor
    img = torch.from_numpy(np.array(pic, mode_to_nptype.get(pic.mode, np.uint8), copy=True))
  File "/home/danielcarias/.local/lib/python3.10/site-packages/PIL/Image.py", line 681, in __array_interface__
    new["data"] = self.tobytes()
  File "/home/danielcarias/.local/lib/python3.10/site-packages/PIL/Image.py", line 746, in tobytes
    e = _getencoder(self.mode, encoder_name, args)
  File "/home/danielcarias/.local/lib/python3.10/site-packages/PIL/Image.py", line 416, in _getencoder
    encoder = getattr(core, encoder_name + "_encoder")
KeyboardInterrupt